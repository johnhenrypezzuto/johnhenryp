}
fs<-sort(f[,1])
print ("95th percentile of largest correlation by chance:")
fs[trunc(.95*nrep)]
print ("average number of correlations significant by chance:")
fs<-sort(f[,2])
mean(fs)
print ("95th percentile number of correlations significant by chance:")
fs[trunc(.95*nrep)]
# save permuation-based p-values
for (i in 1:nrow(results)){
x<-abs(as.numeric(results[i,3]))
results[i,6]<-1-round(match(x,sort(c(f[,1],x)))/(length(f[,1])+1),3)
}
write.csv(results, file="results_8c1a_D_BD.csv")
# 8C1b: Correlations between demographics and hyperbolic (k) discounting
#nrep<-50000
firstdemo = which(colnames(db)=="gender")
lastdemo = which(colnames(db)=="hispanic")
testvar<-db[c(firstdemo:lastdemo)]
# testvar<-testvar %>%
#   dplyr::select(-(SingleParent:Self.Employed))
testvar<-as.matrix(testvar)
tname<-colnames(testvar)
tname
testvar<-as.matrix(testvar)
dv<-db$avg_td_k
dname<-colnames(dv)
dv<-as.matrix(dv)
testvar <- testvar[which(db$consistent==1), ]
dv<-dv[which(db$consistent==1), ]
k<-ncol(testvar)
d<-1
dr<-length(dv)
dname<-"k"
# matrix to hold results
results = matrix(0,k*d,6)
for (i in 1:d){
for (j in 1:k){
results[(i-1)*k+j,1]=tname[j]
results[(i-1)*k+j,2]=dname[i]
}
}
# Correlations
corr.values <- matrix(0,nrow=d,ncol=k)
p.values <- matrix(0,nrow=d,ncol=k)
for (i in 1:k){
ccor<- cor.test(dv, testvar[,i],
method="pearson",
use="pairwise.complete.obs")
corr.values[1,i]<-ccor$estimate
p.values[1,i]<-ccor$p.value
}
acorr.values<-abs(corr.values)
max(acorr.values)
results[,3]=round(corr.values[1,],3)  # save correlations
results[,4]=round(p.values[1,],3)  # save p-values
# BENJAMINI-HOCHBERG P-VALUE ADJUSTMENT
results[,5]<-round(p.adjust(p.values, "BH"), 3)     # save BH-corrected p-values
# Loop to run the simulation
f<-matrix(0,nrow=nrep,ncol=2)
for (j in 1:nrep) {
dvx<-dv[sample(dr)] # reorder the rows of the dv matrix
for (i in 1:k){
ccor<- cor.test(dvx, testvar[,i],
method="pearson",
use="pairwise.complete.obs")
corr.values[1,i]<-ccor$estimate
p.values[1,i]<-ccor$p.value
}
f[j,1]<-max(abs(corr.values))
f[j,2]<-sum(p.values < .05)
}
fs<-sort(f[,1])
print ("95th percentile of largest correlation by chance:")
fs[trunc(.95*nrep)]
print ("average number of correlations significant by chance:")
fs<-sort(f[,2])
mean(fs)
print ("95th percentile number of correlations significant by chance:")
fs[trunc(.95*nrep)]
# save permuation-based p-values
for (i in 1:nrow(results)){
x<-abs(as.numeric(results[i,3]))
results[i,6]<-1-round(match(x,sort(c(f[,1],x)))/(length(f[,1])+1),3)
}
write.csv(results, file="results_8c1b_D_K.csv")
# 8C1c: Correlations between demographics and patience
#nrep<-5000
firstdemo = which(colnames(db)=="gender")
lastdemo = which(colnames(db)=="hispanic")
testvar<-db[c(firstdemo:lastdemo)]
# testvar<-testvar %>%
#   dplyr::select(-(SingleParent:Self.Employed))
testvar<-as.matrix(testvar)
tname<-colnames(testvar)
dv<-db$td.Patience
dname<-colnames(dv)
dv<-as.matrix(dv)
k<-ncol(testvar)
d<-1
dr<-length(dv)
dname<-"Patience"
# matrix to hold results
results = matrix(0,k*d,6)
for (i in 1:d){
for (j in 1:k){
results[(i-1)*k+j,1]=tname[j]
results[(i-1)*k+j,2]=dname[i]
}
}
# Correlations
corr.values <- matrix(0,nrow=d,ncol=k)
p.values <- matrix(0,nrow=d,ncol=k)
for (i in 1:k){
ccor<- cor.test(dv, testvar[,i],
method="pearson",
use="pairwise.complete.obs")
corr.values[1,i]<-ccor$estimate
p.values[1,i]<-ccor$p.value
}
acorr.values<-abs(corr.values)
max(acorr.values)
results[,3]=round(corr.values[1,],3)  # save correlations
results[,4]=round(p.values[1,],3)  # save p-values
# BENJAMINI-HOCHBERG P-VALUE ADJUSTMENT
results[,5]<-round(p.adjust(p.values, "BH"), 3)     # save BH-corrected p-values
# Loop to run the simulation
f<-matrix(0,nrow=nrep,ncol=2)
for (j in 1:nrep) {
dvx<-dv[sample(dr)] # reorder the rows of the dv matrix
for (i in 1:k){
ccor<- cor.test(dvx, testvar[,i],
method="pearson",
use="pairwise.complete.obs")
corr.values[1,i]<-ccor$estimate
p.values[1,i]<-ccor$p.value
}
f[j,1]<-max(abs(corr.values))
f[j,2]<-sum(p.values < .05)
}
fs<-sort(f[,1])
print ("95th percentile of largest correlation by chance:")
fs[trunc(.95*nrep)]
print ("average number of correlations significant by chance:")
fs<-sort(f[,2])
mean(fs)
print ("95th percentile number of correlations significant by chance:")
fs[trunc(.95*nrep)]
# save permuation-based p-values
for (i in 1:nrow(results)){
x<-abs(as.numeric(results[i,3]))
results[i,6]<-1-round(match(x,sort(c(f[,1],x)))/(length(f[,1])+1),3)
}
write.csv(results, file="results_8c1c_D_P.csv")
# 8C1c: Correlations between demographics and patience
#nrep<-5000
firstdemo = which(colnames(db)=="gender")
lastdemo = which(colnames(db)=="hispanic")
testvar<-db[c(firstdemo:lastdemo)]
# testvar<-testvar %>%
#   dplyr::select(-(SingleParent:Self.Employed))
testvar<-as.matrix(testvar)
tname<-colnames(testvar)
###
dv<-db$average.consistent
dname<-colnames(dv)
dv<-as.matrix(dv)
testvar <- testvar[which(db$consistent==1), ]
dv<-dv[which(db$consistent==1), ]
k<-ncol(testvar)
d<-1
dr<-length(dv)
dname<-"Discount Factor (Average)"
####
# matrix to hold results
results = matrix(0,k*d,6)
for (i in 1:d){
for (j in 1:k){
results[(i-1)*k+j,1]=tname[j]
results[(i-1)*k+j,2]=dname[i]
}
}
# Correlations
corr.values <- matrix(0,nrow=d,ncol=k)
p.values <- matrix(0,nrow=d,ncol=k)
for (i in 1:k){
ccor<- cor.test(dv, testvar[,i],
method="pearson",
use="pairwise.complete.obs")
corr.values[1,i]<-ccor$estimate
p.values[1,i]<-ccor$p.value
}
acorr.values<-abs(corr.values)
max(acorr.values)
results[,3]=round(corr.values[1,],3)  # save correlations
results[,4]=round(p.values[1,],3)  # save p-values
# BENJAMINI-HOCHBERG P-VALUE ADJUSTMENT
results[,5]<-round(p.adjust(p.values, "BH"), 3)     # save BH-corrected p-values
# Loop to run the simulation
f<-matrix(0,nrow=nrep,ncol=2)
for (j in 1:nrep) {
dvx<-dv[sample(dr)] # reorder the rows of the dv matrix
for (i in 1:k){
ccor<- cor.test(dvx, testvar[,i],
method="pearson",
use="pairwise.complete.obs")
corr.values[1,i]<-ccor$estimate
p.values[1,i]<-ccor$p.value
}
f[j,1]<-max(abs(corr.values))
f[j,2]<-sum(p.values < .05)
}
fs<-sort(f[,1])
print ("95th percentile of largest correlation by chance:")
fs[trunc(.95*nrep)]
print ("average number of correlations significant by chance:")
fs<-sort(f[,2])
mean(fs)
print ("95th percentile number of correlations significant by chance:")
fs[trunc(.95*nrep)]
# save permuation-based p-values
for (i in 1:nrow(results)){
x<-abs(as.numeric(results[i,3]))
results[i,6]<-1-round(match(x,sort(c(f[,1],x)))/(length(f[,1])+1),3)
}
write.csv(results, file="results_8c1d_D_DF.csv")
# 8D1a: Correlations between behaviors and beta-delta discounting
#nrep<-50000
firstbeh = which(colnames(db)=="bmi")
lastbeh = which(colnames(db)=="vote.early.all")
testvar<-db[c(firstbeh:lastbeh)]
testvar<-as.matrix(testvar)
tname<-colnames(db[c(firstbeh:lastbeh)])
firstd = which(colnames(db)=="avg_td_beta")
lastd = which(colnames(db)=="avg_td_delta")
dv<-db[c(firstd:lastd)]
dname<-colnames(dv)
dv<-as.matrix(dv)
testvar <- testvar[which(db$consistent==1), ]
dv<-dv[which(db$consistent==1), ]
k<-ncol(testvar)
# matrix to hold results
results = matrix(0,k*ncol(dv),6)
for (i in 1:ncol(dv)){
for (j in 1:k){
results[(i-1)*k+j,1]=tname[j]
results[(i-1)*k+j,2]=dname[i]
}
}
# Correlations
corr.values <- matrix(0,nrow=ncol(dv),ncol=k)
p.values <- matrix(0,nrow=ncol(dv),ncol=k)
for (i in 1:k){
for (m in 1:ncol(dv)){
ccor<- cor.test(dv[,m], testvar[,i],
method="pearson",
use="pairwise.complete.obs")
corr.values[m,i]<-ccor$estimate
p.values[m,i]<-ccor$p.value
}
}
acorr.values<-abs(corr.values)
max(acorr.values)
for (m in 1:ncol(dv)){
results[((m-1)*k+1):((m-1)*k+k),3]=round(corr.values[m,],3)  # save correlations
results[((m-1)*k+1):((m-1)*k+k),4]=round(p.values[m,],3)  # save p-values
}
# BENJAMINI-HOCHBERG P-VALUE ADJUSTMENT
results[,5]<-round(p.adjust(p.values, "BH"), 3)     # save BH-corrected p-values
# Loop to run the simulation
f<-matrix(0,nrow=nrep,ncol=2)
for (j in 1:nrep) {
dvx<-dv[sample(nrow(dv)), ] # reorder the rows of the dv matrix
for (i in 1:k){
for (m in 1:ncol(dv)){
ccor<- cor.test(dvx[,m], testvar[,i],
method="pearson",
use="pairwise.complete.obs")
corr.values[m,i]<-ccor$estimate
p.values[m,i]<-ccor$p.value
}
}
f[j,1]<-max(abs(corr.values))
f[j,2]<-sum(p.values < .05)
}
fs<-sort(f[,1])
print ("95th percentile of largest correlation by chance:")
fs[trunc(.95*nrep)]
print ("average number of correlations significant by chance:")
fs<-sort(f[,2])
mean(fs)
print ("95th percentile number of correlations significant by chance:")
fs[trunc(.95*nrep)]
# save permuation-based p-values
for (i in 1:nrow(results)){
x<-abs(as.numeric(results[i,3]))
results[i,6]<-1-round(match(x,sort(c(f[,1],x)))/(length(f[,1])+1),3)
}
write.csv(results, file="results_8d1a_BH_BD.csv")
# 8D1b: Correlations between behaviors and hyperbolic (k) discounting
#nrep<-50000
firstbeh = which(colnames(db)=="bmi")
lastbeh = which(colnames(db)=="vote.early.all")
testvar<-db[c(firstbeh:lastbeh)]
testvar<-as.matrix(testvar)
tname<-colnames(db[c(firstbeh:lastbeh)])
dv<-db$avg_td_k
dname<-colnames(dv)
dv<-as.matrix(dv)
testvar <- testvar[which(db$consistent==1), ]
dv<-dv[which(db$consistent==1), ]
k<-ncol(testvar)
d<-1
dr<-length(dv)
dname<-"k"
# matrix to hold results
results = matrix(0,k*d,6)
for (i in 1:d){
for (j in 1:k){
results[(i-1)*k+j,1]=tname[j]
results[(i-1)*k+j,2]=dname[i]
}
}
# Correlations
corr.values <- matrix(0,nrow=d,ncol=k)
p.values <- matrix(0,nrow=d,ncol=k)
for (i in 1:k){
ccor<- cor.test(dv, testvar[,i],
method="pearson",
use="pairwise.complete.obs")
corr.values[1,i]<-ccor$estimate
p.values[1,i]<-ccor$p.value
}
acorr.values<-abs(corr.values)
max(acorr.values)
results[,3]=round(corr.values[1,],3)  # save correlations
results[,4]=round(p.values[1,],3)  # save p-values
# BENJAMINI-HOCHBERG P-VALUE ADJUSTMENT
results[,5]<-round(p.adjust(p.values, "BH"), 3)     # save BH-corrected p-values
# Loop to run the simulation
f<-matrix(0,nrow=nrep,ncol=2)
for (j in 1:nrep) {
dvx<-dv[sample(dr)] # reorder the rows of the dv matrix
for (i in 1:k){
ccor<- cor.test(dvx, testvar[,i],
method="pearson",
use="pairwise.complete.obs")
corr.values[1,i]<-ccor$estimate
p.values[1,i]<-ccor$p.value
}
f[j,1]<-max(abs(corr.values))
f[j,2]<-sum(p.values < .05)
}
fs<-sort(f[,1])
print ("95th percentile of largest correlation by chance:")
fs[trunc(.95*nrep)]
print ("average number of correlations significant by chance:")
fs<-sort(f[,2])
mean(fs)
print ("95th percentile number of correlations significant by chance:")
fs[trunc(.95*nrep)]
# save permuation-based p-values
for (i in 1:nrow(results)){
x<-abs(as.numeric(results[i,3]))
results[i,6]<-1-round(match(x,sort(c(f[,1],x)))/(length(f[,1])+1),3)
}
write.csv(results, file="results_8d1b_BH_K.csv")
# 8D1c: Correlations between behaviors and patience
#nrep<-5000
firstbeh = which(colnames(db)=="bmi")
lastbeh = which(colnames(db)=="vote.early.all")
testvar<-db[c(firstbeh:lastbeh)]
testvar<-as.matrix(testvar)
tname<-colnames(db[c(firstbeh:lastbeh)])
dv<-db$td.Patience
dname<-colnames(dv)
dv<-as.matrix(dv)
k<-ncol(testvar)
d<-1
dr<-length(dv)
dname<-"Patience"
# matrix to hold results
results = matrix(0,k*d,6)
for (i in 1:d){
for (j in 1:k){
results[(i-1)*k+j,1]=tname[j]
results[(i-1)*k+j,2]=dname[i]
}
}
# Correlations
corr.values <- matrix(0,nrow=d,ncol=k)
p.values <- matrix(0,nrow=d,ncol=k)
for (i in 1:k){
ccor<- cor.test(dv, testvar[,i],
method="pearson",
use="pairwise.complete.obs")
corr.values[1,i]<-ccor$estimate
p.values[1,i]<-ccor$p.value
}
acorr.values<-abs(corr.values)
max(acorr.values)
results[,3]=round(corr.values[1,],3)  # save correlations
results[,4]=round(p.values[1,],3)  # save p-values
# BENJAMINI-HOCHBERG P-VALUE ADJUSTMENT
results[,5]<-round(p.adjust(p.values, "BH"), 3)     # save BH-corrected p-values
?p.adjust
# Loop to run the simulation
f<-matrix(0,nrow=nrep,ncol=2)
for (j in 1:nrep) {
dvx<-dv[sample(dr)] # reorder the rows of the dv matrix
for (i in 1:k){
ccor<- cor.test(dvx, testvar[,i],
method="pearson",
use="pairwise.complete.obs")
corr.values[1,i]<-ccor$estimate
p.values[1,i]<-ccor$p.value
}
f[j,1]<-max(abs(corr.values))
f[j,2]<-sum(p.values < .05)
}
fs<-sort(f[,1])
print ("95th percentile of largest correlation by chance:")
fs[trunc(.95*nrep)]
print ("average number of correlations significant by chance:")
fs<-sort(f[,2])
mean(fs)
print ("95th percentile number of correlations significant by chance:")
fs[trunc(.95*nrep)]
# save permuation-based p-values
for (i in 1:nrow(results)){
x<-abs(as.numeric(results[i,3]))
results[i,6]<-1-round(match(x,sort(c(f[,1],x)))/(length(f[,1])+1),3)
}
write.csv(results, file="results_8d1c_BH_P.csv")
# 8D1c: Correlations between behaviors and discount factor
#nrep<-5000
firstbeh = which(colnames(db)=="bmi")
lastbeh = which(colnames(db)=="vote.early.all")
testvar<-db[c(firstbeh:lastbeh)]
testvar<-as.matrix(testvar)
tname<-colnames(db[c(firstbeh:lastbeh)])
dv<-db$average.consistent
dname<-colnames(dv)
dv<-as.matrix(dv)
testvar <- testvar[which(db$consistent==1), ]
dv<-dv[which(db$consistent==1), ]
k<-ncol(testvar)
d<-1
dr<-length(dv)
dname<-"Discount Factor (Average)"
# matrix to hold results
results = matrix(0,k*d,6)
for (i in 1:d){
for (j in 1:k){
results[(i-1)*k+j,1]=tname[j]
results[(i-1)*k+j,2]=dname[i]
}
}
# Correlations
corr.values <- matrix(0,nrow=d,ncol=k)
p.values <- matrix(0,nrow=d,ncol=k)
for (i in 1:k){
ccor<- cor.test(dv, testvar[,i],
method="pearson",
use="pairwise.complete.obs")
corr.values[1,i]<-ccor$estimate
p.values[1,i]<-ccor$p.value
}
acorr.values<-abs(corr.values)
max(acorr.values)
results[,3]=round(corr.values[1,],3)  # save correlations
results[,4]=round(p.values[1,],3)  # save p-values
# BENJAMINI-HOCHBERG P-VALUE ADJUSTMENT
results[,5]<-round(p.adjust(p.values, "BH"), 3)     # save BH-corrected p-values
# Loop to run the simulation
f<-matrix(0,nrow=nrep,ncol=2)
for (j in 1:nrep) {
dvx<-dv[sample(dr)] # reorder the rows of the dv matrix
for (i in 1:k){
ccor<- cor.test(dvx, testvar[,i],
method="pearson",
use="pairwise.complete.obs")
corr.values[1,i]<-ccor$estimate
p.values[1,i]<-ccor$p.value
}
f[j,1]<-max(abs(corr.values))
f[j,2]<-sum(p.values < .05)
}
fs<-sort(f[,1])
print ("95th percentile of largest correlation by chance:")
fs[trunc(.95*nrep)]
print ("average number of correlations significant by chance:")
fs<-sort(f[,2])
mean(fs)
print ("95th percentile number of correlations significant by chance:")
fs[trunc(.95*nrep)]
# save permuation-based p-values
for (i in 1:nrow(results)){
x<-abs(as.numeric(results[i,3]))
results[i,6]<-1-round(match(x,sort(c(f[,1],x)))/(length(f[,1])+1),3)
}
write.csv(results, file="results_8d1d_BH_DF.csv")
(proc.time() - ptm)[3]/60
library(tidyverse)
library(psych)
2 + 2
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
blogdown:::serve_site()
